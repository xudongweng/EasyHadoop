dfs.nameservices=ns
dfs.ha.namenodes.ns=nn1,nn2
dfs.namenode.rpc-address.ns.nn1=${host1}:9000
dfs.namenode.http-address.ns.nn1=${host1}:50070
dfs.namenode.rpc-address.ns.nn2=${host2}:9000
dfs.namenode.http-address.ns.nn2=${host2}:50070
dfs.namenode.shared.edits.dir=qjournal://${host1}:8485;${host2}:8485;${host2}:8485/ns
dfs.journalnode.edits.dir=/data/hadoop/journal
dfs.ha.automatic-failover.enabled.ns=true
dfs.client.failover.proxy.provider.ns=org.apache.hadoop.hdfs.server.namenode.ha.ConfiguredFailoverProxyProvider
dfs.ha.fencing.methods=shell(/bin/true)
dfs.permissions.enable=false
dfs.permissions=false
dfs.namenode.name.dir=/data/hadoop/hdfs/name
dfs.datanode.data.dir=/data/hadoop/hdfs/data
dfs.replication=2
dfs.webhdfs.enabled=true